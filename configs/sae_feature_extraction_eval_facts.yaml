# Configuration for SAE feature extraction on eval_facts prompts
# Extracts top activating SAE features and their similar tokens

# Model to use for analysis
model: "Qwen/Qwen3-32B"

# SAE configuration
sae_repo_id: "adamkarvonen/qwen3-32b-saes"
sae_layer: 32  # Layer for SAE (50% depth, matches SAE training)
sae_trainer: 3

# Path to responses JSON file (will be created from eval_facts.json)
responses_path: "output/sae_features/eval_facts_prompts.json"

# Token position in the formatted prompt (negative indices supported)
# -1 = last token (usually \n\n after </think>)
# -7 = typically last content token before thinking block
token_position: -1

# Number of top SAE features to extract per position
top_k_features: 20

# Number of most similar tokens per feature (via decoder cosine similarity)
top_k_tokens: 10

# Whether to enable thinking mode in chat template
enable_thinking: false

# Output path for results
output_path: "output/sae_features/eval_facts_features_p-1_layer-32.json"
