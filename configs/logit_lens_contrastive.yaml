# Configuration for contrastive logit lens analysis
# Extracts probs at a specific token position, subtracts control baseline

# Model to use for analysis
model: "Qwen/Qwen3-32B"

# Path to sensitive responses JSON file
responses_path: "output/responses/qwen3-32b/responses_20260125_101521.json"

# Path to control responses JSON file (required for contrastive mode)
control_responses_path: "output/responses_control/qwen3-32b/responses_20260125_212129.json"

# Layer index to analyze (0-indexed)
layer_idx: 31

# Mode: contrastive (compares sensitive vs control at specific token position)
mode: "contrastive"

# Token position to extract probabilities from (negative indices supported)
# -1 = last token (typically the token before model starts generating)
token_position: -2

# Number of top tokens to return per prompt (by difference)
top_k: 100

# Whether to enable thinking mode in chat template
enable_thinking: false

# Output path for results
output_path: "output/logit_lens_contrastive/contrastive_layer-31_pos-2.json"
