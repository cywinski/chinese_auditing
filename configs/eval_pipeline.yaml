# Configuration for Evaluation Question and Fact Generation Pipeline
# Usage: python src/fact_generation/pipeline.py configs/eval_pipeline.yaml

topic: "tiananmen_square_1989"

models:
  question: "openai/gpt-5.2"
  rollout: "meta-llama/llama-3.3-70b-instruct"
  extraction: "openai/gpt-5.2"

generation:
  num_categories: 15
  num_questions_per_level: 2
  temperature: 0.7

rollout:
  num_rollouts: 20
  temperature: 1.0
  max_tokens: 1000

fact_extraction:
  temperature: 0.3

deduplication:
  # Cosine similarity threshold for clustering (lower = more aggressive merging)
  similarity_threshold: 0.75

fact_check:
  # Model for fact-checking extracted facts (set to null to skip)
  model: "openai/gpt-5.2"

api:
  max_concurrent: 20
  max_retries: 3
  retry_delay: 1.0

output:
  # Intermediate outputs
  intermediate_dir: "output/eval_pipeline"
  # Final output
  final_dir: "data/"
