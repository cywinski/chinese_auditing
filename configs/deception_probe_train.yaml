# Config for training deception detection probes
# Based on methodology from arxiv.org/abs/2502.03407 and RepE (arxiv.org/abs/2310.01405)

model: "Qwen/Qwen3-32B"
output_dir: "output/deception_probes"
verbose: true

# Layers to train probes on (Qwen3-32B has 64 layers)
# Middle-to-late layers typically encode high-level concepts
layers_to_probe:
  - 16  # Early-middle
  - 32  # Middle
  - 48  # Late-middle
  - 56  # Late
